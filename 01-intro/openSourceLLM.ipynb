{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3119d13b-7110-41db-aa91-a5bf35118beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in natural language processing (NLP) as they enable efficient and accurate text analysis, generation, and understanding. The importance of fast language models can be seen in several areas:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation software. These models can quickly process and respond to user input, making them more interactive and user-friendly.\n",
      "2. **Improved User Experience**: Fast language models can reduce latency and improve the overall user experience. For example, in speech-to-text systems, fast language models can quickly transcribe spoken words, allowing users to see their speech in real-time.\n",
      "3. **Increased Productivity**: Fast language models can automate tasks such as text summarization, sentiment analysis, and language translation, freeing up human resources for more complex and creative tasks.\n",
      "4. **Enhanced Customer Service**: Fast language models can power customer service chatbots, enabling them to quickly respond to customer inquiries and provide personalized support.\n",
      "5. **Competitive Advantage**: Companies that adopt fast language models can gain a competitive advantage by providing faster and more accurate language-related services, such as language translation, text analysis, and content generation.\n",
      "6. **Research and Development**: Fast language models can accelerate research and development in areas such as NLP, machine learning, and artificial intelligence, enabling researchers to quickly test and refine their ideas.\n",
      "7. **Scalability**: Fast language models can handle large volumes of text data, making them suitable for applications such as text analysis, sentiment analysis, and entity recognition.\n",
      "8. **Cost Savings**: Fast language models can reduce the computational resources required for language processing, leading to cost savings and increased efficiency.\n",
      "\n",
      "Some of the key applications of fast language models include:\n",
      "\n",
      "1. **Virtual assistants**: Siri, Google Assistant, Alexa\n",
      "2. **Language translation software**: Google Translate, Microsoft Translator\n",
      "3. **Chatbots**: Customer service, tech support, and entertainment bots\n",
      "4. **Text analysis**: Sentiment analysis, entity recognition, and topic modeling\n",
      "5. **Content generation**: Automated content creation, such as news articles and social media posts\n",
      "6. **Speech-to-text systems**: Transcription services, voice assistants, and voice-controlled devices\n",
      "\n",
      "To achieve fast language models, researchers and developers use various techniques, such as:\n",
      "\n",
      "1. **Model pruning**: Reducing the size of the model while maintaining its accuracy\n",
      "2. **Knowledge distillation**: Transferring knowledge from a large model to a smaller one\n",
      "3. **Quantization**: Representing model weights and activations using fewer bits\n",
      "4. **Efficient architectures**: Designing models with fewer parameters and faster computation\n",
      "5. **Parallelization**: Using multiple processing units to speed up computation\n",
      "\n",
      "Overall, fast language models are essential for building efficient, accurate, and scalable NLP applications that can handle the demands of real-time processing and large volumes of text data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7c7aa9-db75-4e39-9e34-6e428760d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e003b5f-f976-4302-bd5e-475c46e33cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7bb6ec-9767-4851-99ed-9fc96a8bb0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '5fc70cbb6240', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'xh6dAuvkQdCmuXsXB2KOFQ', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901edeeb-e61b-4ced-a3c7-e269bd436906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088c2afd-c9ae-43ab-8ae9-208fd05db092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd54e789d4f04657bc170c863a615e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fc56d8-7d41-4ff9-9d03-a34b050c54dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\", 'section': 'General course-related questions', 'question': 'Certificate - Can I follow the course in a self-paced mode and get a certificate?', 'course': 'data-engineering-zoomcamp'}, {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.', 'section': 'General course-related questions', 'question': 'Course - Can I get support if I take the course in the self-paced mode?', 'course': 'data-engineering-zoomcamp'}, {'text': 'from pyarrow.parquet import ParquetFile\\npf = ParquetFile(\\'fhvhv_tripdata_2021-01.parquet\\')\\n#pyarrow builds tables, not dataframes\\ntbl_small = next(pf.iter_batches(batch_size = 1000))\\n#this function converts the table to a dataframe of manageable size\\ndf = tbl_small.to_pandas()\\nAlternatively without PyArrow:\\ndf = spark.read.parquet(\\'fhvhv_tripdata_2021-01.parquet\\')\\ndf1 = df.sort(\\'DOLocationID\\').limit(1000)\\npdf = df1.select(\"*\").toPandas()\\ngcsu', 'section': 'Module 5: pyspark', 'question': 'How can I read a small number of rows from the parquet file directly?', 'course': 'data-engineering-zoomcamp'}, {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.', 'section': 'General course-related questions', 'question': 'How can we contribute to the course?', 'course': 'data-engineering-zoomcamp'}, {'text': 'Alternatively, you can switch to in-file storage with:', 'section': 'Workshop 1 - dlthub', 'question': 'How can I use DuckDB In-Memory database with dlt ?', 'course': 'data-engineering-zoomcamp'}]\n"
     ]
    }
   ],
   "source": [
    "query = 'how can I get the certificate?'\n",
    "\n",
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    result_docs = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return result_docs\n",
    "\n",
    "search_results = elastic_search(query)\n",
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c46690c-9953-494d-8335-96d9d7b8993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    if the CONTEXT doesn’t contain the answer, output NONE\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "    # 这个 strip() 的作用是：去掉字符串首尾的空白字符（包括换行符、空格、制表符 \\t 等）。\n",
    "    \n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion:{doc['question']}\\nanswer:{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9dbcd95-1ba3-4e69-a9f8-8df9263b54e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b65525a8-d667-475e-85f4-55519ace075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To get a certificate, you need to finish the course with a \"live\" cohort, as certificates are not awarded for the self-paced mode. This is because you need to peer-review capstone(s) after submitting a project, which can only be done when the course is running.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = build_prompt(query, search_results)\n",
    "answer = llm(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f0c7b-5f2e-4824-a7a5-83933e4ca3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
